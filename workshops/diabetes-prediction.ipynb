{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Diabetes \n",
    "[data is here](/data/diabetes/).  (From UCI repository)\n",
    "\n",
    "Sample Data:\n",
    "```\n",
    "+---+---+---+---+---+----+-----+---+-------+\n",
    "|  a|  b|  c|  d|  e|   f|    g|  h|outcome|\n",
    "+---+---+---+---+---+----+-----+---+-------+\n",
    "|  6|148| 72| 35|  0|33.6|0.627| 50|      1|\n",
    "|  1| 85| 66| 29|  0|26.6|0.351| 31|      0|\n",
    "|  8|183| 64|  0|  0|23.3|0.672| 32|      1|\n",
    "|  1| 89| 66| 23| 94|28.1|0.167| 21|      0|\n",
    "|  0|137| 40| 35|168|43.1|2.288| 33|      1|\n",
    "|  5|116| 74|  0|  0|25.6|0.201| 30|      0|\n",
    "```\n",
    "\n",
    "- attributes : 8\n",
    "- target variable : 1\n",
    "- number of observations : 768\n",
    "\n",
    "Inputs:\n",
    "- a :  Number of times pregnant\n",
    "- b :  Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "- c :  Diastolic blood pressure (mm Hg)\n",
    "- d :  Triceps skin fold thickness (mm)\n",
    "- e :  2-Hour serum insulin (mu U/ml)\n",
    "- f :  Body mass index (weight in kg/(height in m)^2)\n",
    "- g :  Diabetes pedigree function\n",
    "- h :  Age (years)\n",
    "\n",
    "Output:\n",
    "- outcome : 0 or 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /Users/sujee/spark\n",
      "Spark config:\n",
      "\t executor.memory=2g\n",
      "\tsome_property=some_value\n",
      "\tspark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\tspark.sql.warehouse.dir=/var/folders/lp/qm_skljd2hl4xtps5vw0tdgm0000gn/T/tmpvsry5p6_\n",
      "\tspark.submit.deployMode=client\n",
      "\tspark.ui.showConsoleProgress=true\n",
      "Spark UI running on port 4041\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.18.108:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x115bc6470>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record count  768\n",
      "root\n",
      " |-- a: integer (nullable = true)\n",
      " |-- b: integer (nullable = true)\n",
      " |-- c: integer (nullable = true)\n",
      " |-- d: integer (nullable = true)\n",
      " |-- e: integer (nullable = true)\n",
      " |-- f: double (nullable = true)\n",
      " |-- g: double (nullable = true)\n",
      " |-- h: integer (nullable = true)\n",
      " |-- outcome: integer (nullable = true)\n",
      "\n",
      "+---+---+---+---+---+----+-----+---+-------+\n",
      "|  a|  b|  c|  d|  e|   f|    g|  h|outcome|\n",
      "+---+---+---+---+---+----+-----+---+-------+\n",
      "|  6|148| 72| 35|  0|33.6|0.627| 50|      1|\n",
      "|  1| 85| 66| 29|  0|26.6|0.351| 31|      0|\n",
      "|  8|183| 64|  0|  0|23.3|0.672| 32|      1|\n",
      "|  1| 89| 66| 23| 94|28.1|0.167| 21|      0|\n",
      "|  0|137| 40| 35|168|43.1|2.288| 33|      1|\n",
      "|  5|116| 74|  0|  0|25.6|0.201| 30|      0|\n",
      "|  3| 78| 50| 32| 88|31.0|0.248| 26|      1|\n",
      "| 10|115|  0|  0|  0|35.3|0.134| 29|      0|\n",
      "|  2|197| 70| 45|543|30.5|0.158| 53|      1|\n",
      "|  8|125| 96|  0|  0| 0.0|0.232| 54|      1|\n",
      "|  4|110| 92|  0|  0|37.6|0.191| 30|      0|\n",
      "| 10|168| 74|  0|  0|38.0|0.537| 34|      1|\n",
      "| 10|139| 80|  0|  0|27.1|1.441| 57|      0|\n",
      "|  1|189| 60| 23|846|30.1|0.398| 59|      1|\n",
      "|  5|166| 72| 19|175|25.8|0.587| 51|      1|\n",
      "|  7|100|  0|  0|  0|30.0|0.484| 32|      1|\n",
      "|  0|118| 84| 47|230|45.8|0.551| 31|      1|\n",
      "|  7|107| 74|  0|  0|29.6|0.254| 31|      1|\n",
      "|  1|103| 30| 38| 83|43.3|0.183| 33|      0|\n",
      "|  1|115| 70| 30| 96|34.6|0.529| 32|      1|\n",
      "+---+---+---+---+---+----+-----+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Reading data\n",
    "data = spark.read.csv(\"/data/diabetes/pima-indians-diabetes-data.csv\", header=True, inferSchema=True)\n",
    "print(\"record count \", data.count())\n",
    "data.printSchema()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform some data exploration\n",
    "slice and dice data and see how the data is formed.   \n",
    "For example, try to print the distribution of 'outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>768</td>\n",
       "      <td>3.8450520833333335</td>\n",
       "      <td>3.36957806269887</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>768</td>\n",
       "      <td>120.89453125</td>\n",
       "      <td>31.97261819513622</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>768</td>\n",
       "      <td>69.10546875</td>\n",
       "      <td>19.355807170644777</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>768</td>\n",
       "      <td>20.536458333333332</td>\n",
       "      <td>15.952217567727642</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>768</td>\n",
       "      <td>79.79947916666667</td>\n",
       "      <td>115.24400235133803</td>\n",
       "      <td>0</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>768</td>\n",
       "      <td>31.992578124999977</td>\n",
       "      <td>7.884160320375441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>768</td>\n",
       "      <td>0.4718763020833327</td>\n",
       "      <td>0.331328595012775</td>\n",
       "      <td>0.078</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>768</td>\n",
       "      <td>33.240885416666664</td>\n",
       "      <td>11.760231540678689</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outcome</th>\n",
       "      <td>768</td>\n",
       "      <td>0.3489583333333333</td>\n",
       "      <td>0.476951377242799</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                   1                   2      3     4\n",
       "summary  count                mean              stddev    min   max\n",
       "a          768  3.8450520833333335    3.36957806269887      0    17\n",
       "b          768        120.89453125   31.97261819513622      0   199\n",
       "c          768         69.10546875  19.355807170644777      0   122\n",
       "d          768  20.536458333333332  15.952217567727642      0    99\n",
       "e          768   79.79947916666667  115.24400235133803      0   846\n",
       "f          768  31.992578124999977   7.884160320375441    0.0  67.1\n",
       "g          768  0.4718763020833327   0.331328595012775  0.078  2.42\n",
       "h          768  33.240885416666664  11.760231540678689     21    81\n",
       "outcome    768  0.3489583333333333   0.476951377242799      0     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|outcome|count|\n",
      "+-------+-----+\n",
      "|      1|  268|\n",
      "|      0|  500|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TODO\n",
    "data.groupBy('outcome').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+----+-----+---+-------+--------------------+-----+\n",
      "|  a|  b|  c|  d|  e|   f|    g|  h|outcome|            features|label|\n",
      "+---+---+---+---+---+----+-----+---+-------+--------------------+-----+\n",
      "|  6|148| 72| 35|  0|33.6|0.627| 50|      1|[6.0,148.0,72.0,3...|    1|\n",
      "|  1| 85| 66| 29|  0|26.6|0.351| 31|      0|[1.0,85.0,66.0,29...|    0|\n",
      "|  8|183| 64|  0|  0|23.3|0.672| 32|      1|[8.0,183.0,64.0,0...|    1|\n",
      "|  1| 89| 66| 23| 94|28.1|0.167| 21|      0|[1.0,89.0,66.0,23...|    0|\n",
      "|  0|137| 40| 35|168|43.1|2.288| 33|      1|[0.0,137.0,40.0,3...|    1|\n",
      "|  5|116| 74|  0|  0|25.6|0.201| 30|      0|[5.0,116.0,74.0,0...|    0|\n",
      "|  3| 78| 50| 32| 88|31.0|0.248| 26|      1|[3.0,78.0,50.0,32...|    1|\n",
      "| 10|115|  0|  0|  0|35.3|0.134| 29|      0|[10.0,115.0,0.0,0...|    0|\n",
      "|  2|197| 70| 45|543|30.5|0.158| 53|      1|[2.0,197.0,70.0,4...|    1|\n",
      "|  8|125| 96|  0|  0| 0.0|0.232| 54|      1|[8.0,125.0,96.0,0...|    1|\n",
      "|  4|110| 92|  0|  0|37.6|0.191| 30|      0|[4.0,110.0,92.0,0...|    0|\n",
      "| 10|168| 74|  0|  0|38.0|0.537| 34|      1|[10.0,168.0,74.0,...|    1|\n",
      "| 10|139| 80|  0|  0|27.1|1.441| 57|      0|[10.0,139.0,80.0,...|    0|\n",
      "|  1|189| 60| 23|846|30.1|0.398| 59|      1|[1.0,189.0,60.0,2...|    1|\n",
      "|  5|166| 72| 19|175|25.8|0.587| 51|      1|[5.0,166.0,72.0,1...|    1|\n",
      "|  7|100|  0|  0|  0|30.0|0.484| 32|      1|[7.0,100.0,0.0,0....|    1|\n",
      "|  0|118| 84| 47|230|45.8|0.551| 31|      1|[0.0,118.0,84.0,4...|    1|\n",
      "|  7|107| 74|  0|  0|29.6|0.254| 31|      1|[7.0,107.0,74.0,0...|    1|\n",
      "|  1|103| 30| 38| 83|43.3|0.183| 33|      0|[1.0,103.0,30.0,3...|    0|\n",
      "|  1|115| 70| 30| 96|34.6|0.529| 32|      1|[1.0,115.0,70.0,3...|    1|\n",
      "+---+---+---+---+---+----+-----+---+-------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['a','b','c','d','e','f','g','h'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(data)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"outcome\"])\n",
    "featureVector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data count  768\n",
      "training data count  606\n",
      "testing data count  162\n"
     ]
    }
   ],
   "source": [
    "# training & testing\n",
    "(train, test) = featureVector.randomSplit([0.8,0.2], seed=1)\n",
    "print (\"total data count \", featureVector.count())\n",
    "print (\"training data count \", train.count())\n",
    "print (\"testing data count \", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose algorithm\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# SVM\n",
    "algo = LinearSVC(maxIter=500, regParam=0.2)\n",
    "\n",
    "# logistic\n",
    "# algo = LogisticRegression(maxIter=500, regParam=0.1, elasticNetParam=0.8)\n",
    "\n",
    "## add NB\n",
    "# algo = NaiveBayes(smoothing=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.52 ms, sys: 3.34 ms, total: 11.9 ms\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## train the model\n",
    "model = algo.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.05797149057814717,0.017594326116102347,-0.005134748496412873,-0.00030425726906866817,-0.0004355871135062273,0.030156273276020124,0.4532573530091375,0.00787931143346063]\n",
      "Intercept: -4.058328100780903\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model, 'coefficients'):\n",
    "    print(\"Coefficients: \" + str(model.coefficients))\n",
    "\n",
    "if hasattr(model, 'intercept'):\n",
    "    print(\"Intercept: \" + str(model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[0.0,78.0,88.0,29...|    0|       0.0|\n",
      "|[0.0,93.0,60.0,0....|    0|       0.0|\n",
      "|[0.0,97.0,64.0,36...|    0|       0.0|\n",
      "|(8,[1,5,6,7],[99....|    0|       0.0|\n",
      "|[0.0,101.0,64.0,1...|    0|       0.0|\n",
      "|[0.0,104.0,64.0,2...|    0|       0.0|\n",
      "|[0.0,105.0,68.0,2...|    0|       0.0|\n",
      "|[0.0,105.0,90.0,0...|    0|       0.0|\n",
      "|[0.0,107.0,60.0,2...|    0|       0.0|\n",
      "|[0.0,108.0,68.0,2...|    0|       0.0|\n",
      "|[0.0,114.0,80.0,3...|    0|       0.0|\n",
      "|[0.0,119.0,66.0,2...|    0|       0.0|\n",
      "|[0.0,137.0,70.0,3...|    0|       0.0|\n",
      "|[0.0,146.0,70.0,0...|    1|       0.0|\n",
      "|[0.0,162.0,76.0,5...|    1|       1.0|\n",
      "|[0.0,177.0,60.0,2...|    1|       1.0|\n",
      "|[0.0,179.0,90.0,2...|    1|       1.0|\n",
      "|[0.0,180.0,78.0,6...|    1|       1.0|\n",
      "|[1.0,0.0,74.0,20....|    0|       0.0|\n",
      "|[1.0,73.0,50.0,10...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = model.transform(test)\n",
    "predictions.select(['features', 'label', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC  0.8832772166105496\n"
     ]
    }
   ],
   "source": [
    "## Evalauation\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print (\"AUC \", evaluator.evaluate(predictions))  #AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|label|  0|  1|\n",
      "+-----+---+---+\n",
      "|    0| 93|  6|\n",
      "|    1| 30| 33|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training internals\n",
    "if hasattr(model, 'summary'):\n",
    "    print(\"total iterations \", model.summary.totalIterations)\n",
    "    print()\n",
    "    print(\"objective history : \", model.summary.objectiveHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
