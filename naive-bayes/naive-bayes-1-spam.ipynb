{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md)\n",
    "\n",
    "# Naive Bayes Spam Filtering\n",
    "\n",
    "### Overview\n",
    "\n",
    "We all hate spam, so developing a classifier to classify email as spam or not spam is useful.  \n",
    "\n",
    "### Builds on\n",
    "None\n",
    "\n",
    "### Run time\n",
    "approx. 20-30 minutes\n",
    "\n",
    "### Notes\n",
    "\n",
    "PySpark has a class called NaiveBayes that can be used to do Naive Bayes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /Users/sujee/spark\n",
      "Spark config:\n",
      "\t spark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\texecutor.memory=2g\n",
      "\tspark.sql.warehouse.dir=/var/folders/lp/qm_skljd2hl4xtps5vw0tdgm0000gn/T/tmp9058zjrn\n",
      "\tsome_property=some_value\n",
      "Spark UI running on port 4040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://sujee-mbp-2.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x114802f28>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Let's load the dataframe\n",
    "\n",
    "We will load the dataframe into spark.  Since the outcome label is \"ham\" or \"spam\", we'll just call it label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 ms, sys: 1.17 ms, total: 3.08 ms\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = spark.read.format(\"csv\").\\\n",
    "          option('header','true').\\\n",
    "          option('delimiter', '\\t').\\\n",
    "          option('inferSchema', 'true').\\\n",
    "          load(\"/data/spam/SMSSpamCollection.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records count : 5,574\n",
      "root\n",
      " |-- isspam: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+------+--------------------+\n",
      "|isspam|                text|\n",
      "+------+--------------------+\n",
      "|   ham|Go until jurong p...|\n",
      "|   ham|Ok lar... Joking ...|\n",
      "|  spam|Free entry in 2 a...|\n",
      "|   ham|U dun say so earl...|\n",
      "|   ham|Nah I don't think...|\n",
      "|  spam|FreeMsg Hey there...|\n",
      "|   ham|Even my brother i...|\n",
      "|   ham|As per your reque...|\n",
      "|  spam|WINNER!! As a val...|\n",
      "|  spam|Had your mobile 1...|\n",
      "|   ham|I'm gonna be home...|\n",
      "|  spam|SIX chances to wi...|\n",
      "|  spam|URGENT! You have ...|\n",
      "|   ham|I've been searchi...|\n",
      "|   ham|I HAVE A DATE ON ...|\n",
      "|  spam|XXXMobileMovieClu...|\n",
      "|   ham|Oh k...i'm watchi...|\n",
      "|   ham|Eh u remember how...|\n",
      "|   ham|Fine if thats th...|\n",
      "|  spam|England v Macedon...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"records count : {:,}\".format(dataset.count()))\n",
    "\n",
    "dataset.printSchema()\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|isspam|count|\n",
      "+------+-----+\n",
      "|   ham| 4827|\n",
      "|  spam|  747|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Count spam/ham\n",
    "dataset.groupby(\"isspam\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Vectorize using tf/idf\n",
    "\n",
    "Let's use tf/idf for vecorization at first.  TF/IDF will take and count the instances of each term, and then divide by the total frequecy of that term in the entire dataset.  \n",
    "\n",
    "This leads to very highly dimensional data, because every word in the document will lead to a dimension in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|isspam|                text|               words|\n",
      "+------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|[go, until, juron...|\n",
      "|   ham|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|  spam|Free entry in 2 a...|[free, entry, in,...|\n",
      "|   ham|U dun say so earl...|[u, dun, say, so,...|\n",
      "|   ham|Nah I don't think...|[nah, i, don't, t...|\n",
      "|  spam|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|   ham|Even my brother i...|[even, my, brothe...|\n",
      "|   ham|As per your reque...|[as, per, your, r...|\n",
      "|  spam|WINNER!! As a val...|[winner!!, as, a,...|\n",
      "|  spam|Had your mobile 1...|[had, your, mobil...|\n",
      "|   ham|I'm gonna be home...|[i'm, gonna, be, ...|\n",
      "|  spam|SIX chances to wi...|[six, chances, to...|\n",
      "|  spam|URGENT! You have ...|[urgent!, you, ha...|\n",
      "|   ham|I've been searchi...|[i've, been, sear...|\n",
      "|   ham|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "|  spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|   ham|Oh k...i'm watchi...|[oh, k...i'm, wat...|\n",
      "|   ham|Eh u remember how...|[eh, u, remember,...|\n",
      "|   ham|Fine if thats th...|[fine, if, thats...|\n",
      "|  spam|England v Macedon...|[england, v, mace...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "## TODO : split the text into words\n",
    "## Hint : outputCol = 'words'\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(dataset)\n",
    "wordsData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|isspam|                text|               words|         rawFeatures|            features|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|[go, until, juron...|(2000,[7,77,165,2...|(2000,[7,77,165,2...|\n",
      "|   ham|Ok lar... Joking ...|[ok, lar..., joki...|(2000,[20,484,131...|(2000,[20,484,131...|\n",
      "|  spam|Free entry in 2 a...|[free, entry, in,...|(2000,[30,128,140...|(2000,[30,128,140...|\n",
      "|   ham|U dun say so earl...|[u, dun, say, so,...|(2000,[57,372,381...|(2000,[57,372,381...|\n",
      "|   ham|Nah I don't think...|[nah, i, don't, t...|(2000,[388,426,89...|(2000,[388,426,89...|\n",
      "|  spam|FreeMsg Hey there...|[freemsg, hey, th...|(2000,[68,91,98,9...|(2000,[68,91,98,9...|\n",
      "|   ham|Even my brother i...|[even, my, brothe...|(2000,[47,48,57,2...|(2000,[47,48,57,2...|\n",
      "|   ham|As per your reque...|[as, per, your, r...|(2000,[272,388,39...|(2000,[272,388,39...|\n",
      "|  spam|WINNER!! As a val...|[winner!!, as, a,...|(2000,[74,153,388...|(2000,[74,153,388...|\n",
      "|  spam|Had your mobile 1...|[had, your, mobil...|(2000,[82,279,343...|(2000,[82,279,343...|\n",
      "|   ham|I'm gonna be home...|[i'm, gonna, be, ...|(2000,[26,263,333...|(2000,[26,263,333...|\n",
      "|  spam|SIX chances to wi...|[six, chances, to...|(2000,[15,46,214,...|(2000,[15,46,214,...|\n",
      "|  spam|URGENT! You have ...|[urgent!, you, ha...|(2000,[68,196,388...|(2000,[68,196,388...|\n",
      "|   ham|I've been searchi...|[i've, been, sear...|(2000,[39,185,317...|(2000,[39,185,317...|\n",
      "|   ham|I HAVE A DATE ON ...|[i, have, a, date...|(2000,[44,82,712,...|(2000,[44,82,712,...|\n",
      "|  spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|(2000,[78,273,388...|(2000,[78,273,388...|\n",
      "|   ham|Oh k...i'm watchi...|[oh, k...i'm, wat...|(2000,[275,629,14...|(2000,[275,629,14...|\n",
      "|   ham|Eh u remember how...|[eh, u, remember,...|(2000,[147,236,23...|(2000,[147,236,23...|\n",
      "|   ham|Fine if thats th...|[fine, if, thats...|(2000,[80,170,296...|(2000,[80,170,296...|\n",
      "|  spam|England v Macedon...|[england, v, mace...|(2000,[9,19,45,38...|(2000,[9,19,45,38...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## compute the hash of words\n",
    "\n",
    "## we will tweak this later\n",
    "number_of_features = 2000\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=number_of_features)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|isspam|                text|            features|\n",
      "+------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|(2000,[7,77,165,2...|\n",
      "|   ham|Ok lar... Joking ...|(2000,[20,484,131...|\n",
      "|  spam|Free entry in 2 a...|(2000,[30,128,140...|\n",
      "|   ham|U dun say so earl...|(2000,[57,372,381...|\n",
      "|   ham|Nah I don't think...|(2000,[388,426,89...|\n",
      "|  spam|FreeMsg Hey there...|(2000,[68,91,98,9...|\n",
      "|   ham|Even my brother i...|(2000,[47,48,57,2...|\n",
      "|   ham|As per your reque...|(2000,[272,388,39...|\n",
      "|  spam|WINNER!! As a val...|(2000,[74,153,388...|\n",
      "|  spam|Had your mobile 1...|(2000,[82,279,343...|\n",
      "|   ham|I'm gonna be home...|(2000,[26,263,333...|\n",
      "|  spam|SIX chances to wi...|(2000,[15,46,214,...|\n",
      "|  spam|URGENT! You have ...|(2000,[68,196,388...|\n",
      "|   ham|I've been searchi...|(2000,[39,185,317...|\n",
      "|   ham|I HAVE A DATE ON ...|(2000,[44,82,712,...|\n",
      "|  spam|XXXMobileMovieClu...|(2000,[78,273,388...|\n",
      "|   ham|Oh k...i'm watchi...|(2000,[275,629,14...|\n",
      "|   ham|Eh u remember how...|(2000,[147,236,23...|\n",
      "|   ham|Fine if thats th...|(2000,[80,170,296...|\n",
      "|  spam|England v Macedon...|(2000,[9,19,45,38...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"isspam\", \"text\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a numeric label out of the string column \"isspam.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+--------------------+\n",
      "|                text|isspam|label|            features|\n",
      "+--------------------+------+-----+--------------------+\n",
      "|Go until jurong p...|   ham|  0.0|(2000,[7,77,165,2...|\n",
      "|Ok lar... Joking ...|   ham|  0.0|(2000,[20,484,131...|\n",
      "|Free entry in 2 a...|  spam|  1.0|(2000,[30,128,140...|\n",
      "|U dun say so earl...|   ham|  0.0|(2000,[57,372,381...|\n",
      "|Nah I don't think...|   ham|  0.0|(2000,[388,426,89...|\n",
      "|FreeMsg Hey there...|  spam|  1.0|(2000,[68,91,98,9...|\n",
      "|Even my brother i...|   ham|  0.0|(2000,[47,48,57,2...|\n",
      "|As per your reque...|   ham|  0.0|(2000,[272,388,39...|\n",
      "|WINNER!! As a val...|  spam|  1.0|(2000,[74,153,388...|\n",
      "|Had your mobile 1...|  spam|  1.0|(2000,[82,279,343...|\n",
      "|I'm gonna be home...|   ham|  0.0|(2000,[26,263,333...|\n",
      "|SIX chances to wi...|  spam|  1.0|(2000,[15,46,214,...|\n",
      "|URGENT! You have ...|  spam|  1.0|(2000,[68,196,388...|\n",
      "|I've been searchi...|   ham|  0.0|(2000,[39,185,317...|\n",
      "|I HAVE A DATE ON ...|   ham|  0.0|(2000,[44,82,712,...|\n",
      "|XXXMobileMovieClu...|  spam|  1.0|(2000,[78,273,388...|\n",
      "|Oh k...i'm watchi...|   ham|  0.0|(2000,[275,629,14...|\n",
      "|Eh u remember how...|   ham|  0.0|(2000,[147,236,23...|\n",
      "|Fine if thats th...|   ham|  0.0|(2000,[80,170,296...|\n",
      "|England v Macedon...|  spam|  1.0|(2000,[9,19,45,38...|\n",
      "+--------------------+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "## TODO : Index 'isspam' column into 'label' column\n",
    "## Hint : inputCol = 'isspam',   outputCol = 'label'\n",
    "indexer = StringIndexer(inputCol=\"isspam\", outputCol=\"label\")\n",
    "indexed = indexer.fit(rescaledData).transform(rescaledData)\n",
    "\n",
    "indexed.select(['text', 'isspam', 'label', 'features']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into training and test\n",
    "\n",
    "We will split our dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set count :  4418\n",
      "testing set count :  1156\n"
     ]
    }
   ],
   "source": [
    "# TODO : Split the data into train and test into 80/20\n",
    "(train, test) = indexed.randomSplit([.8, .2])\n",
    "\n",
    "print(\"training set count : \", train.count())\n",
    "print(\"testing set count : \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fit Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "## TODO : create the trainer and set its parameters\n",
    "## Hint : NaiveBayes  (see the class name above)\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starting...\n",
      "training done.\n",
      "CPU times: user 7.32 ms, sys: 2.67 ms, total: 9.98 ms\n",
      "Wall time: 797 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train the model\n",
    "## TODO : fit on training data (hint: train)\n",
    "print(\"training starting...\")\n",
    "model = nb.fit(train)\n",
    "print (\"training done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run test data\n",
    "\n",
    "Let's call .transform on our model to do make predictions on our test data. The output should be contained in the \"prediction\" column, while the correct label will be there in the \"label\" column. \n",
    "\n",
    "We will be able to evaluate our results by comparing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isspam</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>rawFeatures</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>&amp;lt;#&amp;gt;  mins but i had to stop somewhere f...</td>\n",
       "      <td>[, &amp;lt;#&amp;gt;, , mins, but, i, had, to, stop, s...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-236.57647504147462, -252.88586086018597]</td>\n",
       "      <td>[0.9999999174107163, 8.258928376801963e-08]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>and  picking them up from various points</td>\n",
       "      <td>[, and, , picking, them, up, from, various, po...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-217.0008742346316, -253.6499421962386]</td>\n",
       "      <td>[0.9999999999999998, 1.2120262263282667e-16]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>what number do u live at? Is it 11?</td>\n",
       "      <td>[, what, number, do, u, live, at?, is, it, 11?]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-218.10860554362733, -258.4689566910269]</td>\n",
       "      <td>[1.0, 2.962935578863434e-18]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Happy valentines day\" I know its early but i ...</td>\n",
       "      <td>[\"happy, valentines, day\", i, know, its, early...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-706.8283258134346, -799.8643432541411]</td>\n",
       "      <td>[1.0, 3.93523803605778e-41]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Wen u miss someone, the person is definitely ...</td>\n",
       "      <td>[\"wen, u, miss, someone,, the, person, is, def...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.4288230189921...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-716.5227052362972, -766.7611408132099]</td>\n",
       "      <td>[1.0, 1.5195837808258532e-22]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  isspam                                               text  \\\n",
       "0    ham   &lt;#&gt;  mins but i had to stop somewhere f...   \n",
       "1    ham           and  picking them up from various points   \n",
       "2    ham                what number do u live at? Is it 11?   \n",
       "3    ham  \"Happy valentines day\" I know its early but i ...   \n",
       "4    ham  \"Wen u miss someone, the person is definitely ...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [, &lt;#&gt;, , mins, but, i, had, to, stop, s...   \n",
       "1  [, and, , picking, them, up, from, various, po...   \n",
       "2    [, what, number, do, u, live, at?, is, it, 11?]   \n",
       "3  [\"happy, valentines, day\", i, know, its, early...   \n",
       "4  [\"wen, u, miss, someone,, the, person, is, def...   \n",
       "\n",
       "                                         rawFeatures  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  label  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.4288230189921...    0.0   \n",
       "\n",
       "                                rawPrediction  \\\n",
       "0  [-236.57647504147462, -252.88586086018597]   \n",
       "1    [-217.0008742346316, -253.6499421962386]   \n",
       "2   [-218.10860554362733, -258.4689566910269]   \n",
       "3    [-706.8283258134346, -799.8643432541411]   \n",
       "4    [-716.5227052362972, -766.7611408132099]   \n",
       "\n",
       "                                    probability  prediction  \n",
       "0   [0.9999999174107163, 8.258928376801963e-08]         0.0  \n",
       "1  [0.9999999999999998, 1.2120262263282667e-16]         0.0  \n",
       "2                  [1.0, 2.962935578863434e-18]         0.0  \n",
       "3                   [1.0, 3.93523803605778e-41]         0.0  \n",
       "4                 [1.0, 1.5195837808258532e-22]         0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select example rows to display.\n",
    "## TODO : transform on test data (hint : test)\n",
    "predictions_test = model.transform(test)\n",
    "predictions_test.limit(5).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the model\n",
    "\n",
    "Let's look at how our model performs.  We will do an accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.transform(test)\n",
    "predictions_train = model.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy =  0.9692168401991852\n",
      "Test set accuracy =  0.9472318339100346\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "print(\"Training set accuracy = \" , evaluator.evaluate(predictions_train))\n",
    "print(\"Test set accuracy = \" , evaluator.evaluate(predictions_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Confusion MMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|label|  0|  1|\n",
      "+-----+---+---+\n",
      "|  0.0|954| 43|\n",
      "|  1.0| 18|141|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = predictions_test.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label')\n",
    "cm.show()\n",
    "\n",
    "## Can you explain the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_pd = cm.toPandas()\n",
    "cm_pd.set_index(\"label\", inplace=True)\n",
    "# print(cm_pd)\n",
    "\n",
    "# colormaps : cmap=\"YlGnBu\" , cmap=\"Greens\", cmap=\"Blues\",  cmap=\"Reds\"\n",
    "sns.heatmap(cm_pd, annot=True, fmt=',', cmap=\"Blues\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Improve prediction results\n",
    "\n",
    "We used too few features above, and got bad accuracy. Increase the number of features for HashingTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9:  Run your own test\n",
    "\n",
    "Now it's your turn!   Make a new dataframe with some sample test data of your own creation.  Make some \"spammy\" SMSes and some ordinary ones.  See how our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|               words|\n",
      "+--------------------+--------------------+\n",
      "|hey, can we meet ...|[hey,, can, we, m...|\n",
      "|WINNER!  Click he...|[winner!, , click...|\n",
      "|   CHEAP DEGREEES !!|[cheap, degreees,...|\n",
      "|      your text here|  [your, text, here]|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|         rawFeatures|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|hey, can we meet ...|[hey,, can, we, m...|(2000,[238,486,74...|(2000,[238,486,74...|\n",
      "|WINNER!  Click he...|[winner!, , click...|(2000,[388,493,53...|(2000,[388,493,53...|\n",
      "|   CHEAP DEGREEES !!|[cheap, degreees,...|(2000,[119,339,16...|(2000,[119,339,16...|\n",
      "|      your text here|  [your, text, here]|(2000,[1135,1169,...|(2000,[1135,1169,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: make a dataframe with some of your own data.\n",
    "import pandas as pd\n",
    "\n",
    "mydata = pd.DataFrame({'text' : ['hey, can we meet 1 hr later?', \n",
    "                                'WINNER!  Click here to claim your prize !!!!',\n",
    "                                'CHEAP DEGREEES !!', \n",
    "                                'your text here']\n",
    "                         })\n",
    "\n",
    "mydata2 = spark.createDataFrame(mydata)\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "fv = tokenizer.transform(mydata2)\n",
    "fv.show()\n",
    "\n",
    "## NOTE : make sure this 'numFeatures' matches the 'numFeatures' in step-2\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=number_of_features)\n",
    "fv = hashingTF.transform(fv)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "fv = idfModel.transform(fv)\n",
    "fv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                text|prediction|\n",
      "+--------------------+----------+\n",
      "|hey, can we meet ...|       0.0|\n",
      "|WINNER!  Click he...|       1.0|\n",
      "|   CHEAP DEGREEES !!|       1.0|\n",
      "|      your text here|       1.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(fv)\n",
    "predictions.select(['text', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN : How will you defeat this algorithm? :-) \n",
    "\n",
    "If you are spammer, how can you defeat this algorithm?\n",
    "\n",
    "<img src=\"../assets/images/come-tothe-dark-side-iin-we-have-cookies.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "Checkout [Amazon Comprehend](https://us-west-2.console.aws.amazon.com/comprehend/v2/home?region=us-west-2#welcome) to parse natural text and extract meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Word2Vec Instead of TF/IDF\n",
    "\n",
    "We used the TF/IDF encoding. We might get better resu\n",
    "\n",
    "lts if we use Word2Vec instead. Run with word2vec and see if you get a better accuracy rate.\n",
    "\n",
    "Refer to [Spark Word2Vec](https://spark.apache.org/docs/2.2.0/mllib-feature-extraction.html#word2vec) implementation for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
